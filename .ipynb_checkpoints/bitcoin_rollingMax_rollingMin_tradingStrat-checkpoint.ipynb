{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Jupyter Notebook Technical Analysis Demo\n",
    "Data-set URL: https://raw.githubusercontent.com/iamnewneo/ML_For_Trading/master/data/stocks/XOM.csv\n",
    "\n",
    "Let's import some packages that will be helpful for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(symbol, dates):\n",
    "    \"\"\"Read stock data (adjusted close) for given symbols from CSV files.\"\"\"\n",
    "    df = pd.DataFrame(index=dates)\n",
    "     # TODO: Read and join data for each symbol\n",
    "\n",
    "    df_temp = pd.read_csv('data/{}.csv'.format(symbol), usecols=['Timestamp', 'Close'])\n",
    "    df_temp['datetime'] = pd.to_datetime(df_temp['Timestamp'], unit='s')\n",
    "    df_temp = df_temp.set_index('datetime')\n",
    "    df_temp.drop(['Timestamp'], inplace = True, axis = 1)\n",
    "    locs = df_temp.index.indexer_at_time('00:00:00')\n",
    "    df_temp = df_temp.iloc[locs]\n",
    "    df = df.join(df_temp, how='inner')\n",
    "    df['Close'].fillna(method='ffill', inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'data/bitstampfull2.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-920269481551>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[0mtest_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-920269481551>\u001b[0m in \u001b[0;36mtest_run\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mend_date\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'2017-10-20'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0msymbol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'bitstampfull2'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'RollingMean'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrolling_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Close'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-32d4a7fd4cd5>\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(symbol, dates)\u001b[0m\n\u001b[0;32m      4\u001b[0m      \u001b[1;31m# TODO: Read and join data for each symbol\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mdf_temp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/{}.csv'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Timestamp'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Close'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mdf_temp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'datetime'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_temp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Timestamp'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m's'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mdf_temp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_temp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'datetime'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    703\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    704\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 705\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    812\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1043\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1045\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1046\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1682\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1683\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1684\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1686\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'data/bitstampfull2.csv' does not exist"
     ]
    }
   ],
   "source": [
    "def rolling_mean(values, window):\n",
    "    return values.rolling(window = window).mean()\n",
    "\n",
    "def rolling_max(values, window):\n",
    "    return values.rolling(window = window).std()\n",
    "\n",
    "\n",
    "def test_run():\n",
    "    dates = pd.date_range('2015-12-31', '2017-10-19')\n",
    "    start_date='2011-12-31'\n",
    "    end_date='2017-10-20'\n",
    "    symbol = 'bitstampfull2'\n",
    "    data = get_data(symbol, dates)\n",
    "\n",
    "    data['RollingMean'] = rolling_mean(data['Close'], window = 50)\n",
    "    data['RollingMax'] = data['Close'].shift(1).rolling(30, min_periods=30).max()\n",
    "    data['RollingMin'] = data['Close'].shift(1).rolling(30, min_periods=30).min()\n",
    "    data['Buy'] = np.zeros(len(data))\n",
    "    data['Sell'] = np.zeros(len(data))\n",
    "    data.loc[data['RollingMax'] < data['Close'], 'Buy'] = 1\n",
    "    data.loc[data['RollingMin'] > data['Close'], 'Sell'] = -1\n",
    "\n",
    "    fig,ax1 = plt.subplots(figsize=(16, 8))\n",
    "    ax1.plot(data[['Close','RollingMean','RollingMax','RollingMin']])\n",
    "    y = ax1.get_ylim()\n",
    "    ax1.set_ylim(y[0] - (y[1]-y[0])*0.4, y[1])\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_position(matplotlib.transforms.Bbox([[0.1,0.125],[0.9,0.32]]))\n",
    "    ax2.plot(data['Buy'], color='#77dd77')\n",
    "    ax2.plot(data['Sell'], color='#dd4444')\n",
    "    \n",
    "    ax1.xaxis.set_major_locator(\n",
    "    matplotlib.data.index.WeekdayLocator(byweekday=matplotlib.data.index.MO))\n",
    "    ax1.xaxis.set_major_formatter(matplotlib.data.index.DateFormatter('%a %d\\n%b %Y'))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "test_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "# Daily and Cumulative Returns Comparisons for Multiple Stocks\n",
    "\n",
    "Datasets from my github: https://github.com/denisond/technical_analysis/tree/master/data\n",
    "\n",
    "Let's import some packages that will be helpful for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing and visualing our dataset \n",
    "\n",
    "Now we can write a couple of functions to help find our dataset, read it in, and clean it, all for our date range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(symbols, dates):\n",
    "    \"\"\"Read stock data (adjusted close) for given symbols from CSV files.\"\"\"\n",
    "    df = pd.DataFrame(index = dates)\n",
    "    for symbol in symbols:\n",
    "        # Read and join data for each symbol\n",
    "        df_temp = pd.read_csv(\n",
    "            'data/{}.csv'.format(symbol),\n",
    "            index_col = 'Date', parse_dates = True, \n",
    "            usecols = ['Date', 'Adj Close'],\n",
    "            na_values = ['nan'])\n",
    "        df_temp = df_temp.rename(columns = {'Adj Close': symbol})\n",
    "        df = df.join(df_temp, how = 'inner')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we can call these functions to get an idea of what our series looks like at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates = pd.date_range('2012-01-01', '2013-09-10')\n",
    "symbols = ['SPY', 'XOM', 'AAPL']\n",
    "data = get_data(symbols, dates)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Next let's define a simple fcn so we can start visualizing our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_data(df, symbols):\n",
    "    ax = df.plot(figsize = (20, 10))\n",
    "    plt.title('{}, {}, & {} Stock Prices'.format(symbols[0], symbols[1], symbols[2]), fontsize = 20)\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(\"Price\")\n",
    "    ax.tick_params(labelsize = 15)\n",
    "    ax.legend(loc = 'upper left', fontsize = 20)\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_data(data, symbols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Immediately we see a problem when trying to compare two stocks in terms of price. The movements in price of the less expensive stocks(SPDR S&P 500 ETF Trust and XOM) are much harder to detect than those of apple, due to the scale of the y-axis. \n",
    "\n",
    "Daily returns and cumulative returns are two useful metrics for comparing stocks' performances, as well as analyzing the performance one stock by itself. Let's define fcns to create and add these columns to our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def daily_returns(df):\n",
    "    daily_returns = df.copy()\n",
    "    daily_returns = (df/df.shift(1)) - 1\n",
    "    daily_returns.iloc[0] = 0\n",
    "    return daily_returns\n",
    "\n",
    "def cumulative_returns(df):\n",
    "    cumulative_returns = df.copy()\n",
    "    cumulative_returns[1:] = (df[1:]/df.iloc[0].values) - 1\n",
    "    cumulative_returns.iloc[0] = 0\n",
    "    return cumulative_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "daily_returns(data).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cumulative_returns(data).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see above the difference between our two columns: daily returns calculates the percentage change from one day's price to the next, whereas cumulative return calculates the aggregate percentage change in price from the first day in the dataframe. \n",
    "\n",
    "Now let's plot and compare all 3 of our stocks' prices in terms of daily and cumulative returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_data(daily_returns(data), symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_data(cumulative_returns(data), symbols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear from the cumulative returns plot that Apple stock is much more volatile that the other two stocks. In particular, the highest point in the middle of the plot jumps out. I am curious what happened that caused a 9% daily return in the apple stock, so let's find the date and do a quick google search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "daily_returns(data)['AAPL'].idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Searching \"4/25/12 Apple\" returns the follwing link as one of the top hits: http://money.cnn.com/2012/04/25/technology/apple-supplier-stocks/index.htm This article describes the reason for Apple's price rising by 9% -- Apple's 2nd quarter earnings were very high due to higher than expected iPhone sales. These are the types of insights we can draw from daily returns.\n",
    "\n",
    "The cumulative returns plot is also very interesting. Because the prices are normed, we can clearly see Apple outperformed our other stocks during this date-range, whereas before with only the stock price it was much less clear. Moreover, we can see clearly trends that persist amongst all three stocks, perhaps indicating significant economic news or events. These are all things to consider when comparing stocks' performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "# Daily and Cumulative Returns Comparisons for Multiple Stocks\n",
    "\n",
    "Datasets from my github: https://github.com/denisond/technical_analysis/tree/master/data\n",
    "\n",
    "Let's import some packages that will be helpful for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing and visualing our dataset \n",
    "\n",
    "Now we can write a couple of functions to help find our dataset, read it in, and clean it, all for our date range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(symbols, dates):\n",
    "    \"\"\"Read stock data (adjusted close) for given symbols from CSV files.\"\"\"\n",
    "    df = pd.DataFrame(index = dates)\n",
    "    for symbol in symbols:\n",
    "        # Read and join data for each symbol\n",
    "        df_temp = pd.read_csv(\n",
    "            'data/{}.csv'.format(symbol),\n",
    "            index_col = 'Date', parse_dates = True, \n",
    "            usecols = ['Date', 'Adj Close'],\n",
    "            na_values = ['nan'])\n",
    "        df_temp = df_temp.rename(columns = {'Adj Close': symbol})\n",
    "        df = df.join(df_temp, how = 'inner')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we can call these functions to get an idea of what our series looks like at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates = pd.date_range('2012-01-01', '2013-09-10')\n",
    "symbols = ['SPY', 'XOM', 'AAPL']\n",
    "data = get_data(symbols, dates)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Next let's define a simple fcn so we can start visualizing our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_data(df, symbols):\n",
    "    ax = df.plot(figsize = (20, 10))\n",
    "    plt.title('{}, {}, & {} Stock Prices'.format(symbols[0], symbols[1], symbols[2]), fontsize = 20)\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(\"Price\")\n",
    "    ax.tick_params(labelsize = 15)\n",
    "    ax.legend(loc = 'upper left', fontsize = 20)\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_data(data, symbols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Immediately we see a problem when trying to compare two stocks in terms of price. The movements in price of the less expensive stocks(SPDR S&P 500 ETF Trust and XOM) are much harder to detect than those of apple, due to the scale of the y-axis. \n",
    "\n",
    "Daily returns and cumulative returns are two useful metrics for comparing stocks' performances, as well as analyzing the performance one stock by itself. Let's define fcns to create and add these columns to our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def daily_returns(df):\n",
    "    daily_returns = df.copy()\n",
    "    daily_returns = (df/df.shift(1)) - 1\n",
    "    daily_returns.iloc[0] = 0\n",
    "    return daily_returns\n",
    "\n",
    "def cumulative_returns(df):\n",
    "    cumulative_returns = df.copy()\n",
    "    cumulative_returns[1:] = (df[1:]/df.iloc[0].values) - 1\n",
    "    cumulative_returns.iloc[0] = 0\n",
    "    return cumulative_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "daily_returns(data).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cumulative_returns(data).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see above the difference between our two columns: daily returns calculates the percentage change from one day's price to the next, whereas cumulative return calculates the aggregate percentage change in price from the first day in the dataframe. \n",
    "\n",
    "Now let's plot and compare all 3 of our stocks' prices in terms of daily and cumulative returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_data(daily_returns(data), symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_data(cumulative_returns(data), symbols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear from the cumulative returns plot that Apple stock is much more volatile that the other two stocks. In particular, the highest point in the middle of the plot jumps out. I am curious what happened that caused a 9% daily return in the apple stock, so let's find the date and do a quick google search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "daily_returns(data)['AAPL'].idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Searching \"4/25/12 Apple\" returns the follwing link as one of the top hits: http://money.cnn.com/2012/04/25/technology/apple-supplier-stocks/index.htm This article describes the reason for Apple's price rising by 9% -- Apple's 2nd quarter earnings were very high due to higher than expected iPhone sales. These are the types of insights we can draw from daily returns.\n",
    "\n",
    "The cumulative returns plot is also very interesting. Because the prices are normed, we can clearly see Apple outperformed our other stocks during this date-range, whereas before with only the stock price it was much less clear. Moreover, we can see clearly trends that persist amongst all three stocks, perhaps indicating significant economic news or events. These are all things to consider when comparing stocks' performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
